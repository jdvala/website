<!DOCTYPE html>
<html lang="en">





<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="description" content="Training a Long Short Term Memory Network on subset of classes">
  <meta name="keywords" content="blog and jekyll">
  <meta name="author" content="LSTM with 8 Classes | Jay Vala">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#f5f5f5">

  <!-- Twitter Tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="LSTM with 8 Classes | Jay Vala">
  <meta name="twitter:description" content="Training a Long Short Term Memory Network on subset of classes">
  
    <meta property="twitter:image" content="http://localhost:4000/img/leonids-logo.png">
  

  <!-- Open Graph Tags -->
  <meta property="og:type" content="blog">
  <meta property="og:url" content="http://localhost:4000/articles/2018-05/RNN-Sequence-Classification-with-modifications">
  <meta property="og:title" content="LSTM with 8 Classes | Jay Vala">
  <meta property="og:description" content="Training a Long Short Term Memory Network on subset of classes">
  
    <meta property="og:image" content="http://localhost:4000/img/leonids-logo.png">
  
  <title>LSTM with 8 Classes | Jay Vala</title>

  <!-- CSS files -->
  <link rel="stylesheet" href="http://localhost:4000/css/font-awesome.min.css">
  <link rel="stylesheet" href="http://localhost:4000/css/main.css">

  <link rel="canonical" href="http://localhost:4000/articles/2018-05/RNN-Sequence-Classification-with-modifications">
  <link rel="alternate" type="application/rss+xml" title="Jay Vala" href="http://localhost:4000/feed.xml" />

  <!-- Icons -->
  <!-- 16x16 -->
  <link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
  <!-- 32x32 -->
  <link rel="shortcut icon" href="http://localhost:4000/favicon.png">
</head>


<body>
  <div class="row">
    <div class="col s12 m3">
      <div class="table cover">
        

<div class="cover-card table-cell table-middle">
  
  <a href="http://localhost:4000/">
    <img src="http://localhost:4000/img/me.png" alt="" class="avatar">
  </a>
  
  <a href="http://localhost:4000/" class="author_name">Jay Vala</a>
  <span class="author_job">Junior Data Scientist @scoutbee</span>
  <span class="author_bio mbm">Getting the basics right</span>
  <nav class="nav">
    <ul class="nav-list">
      <li class="nav-item">
        <a href="http://localhost:4000/">home</a>
      </li>
       
      <li class="nav-item">
        <a href="http://localhost:4000/archive/">Archive</a>
      </li>
          
      <li class="nav-item">
        <a href="http://localhost:4000/categories/">Categories</a>
      </li>
            
      <li class="nav-item">
        <a href="http://localhost:4000/resume/">Resume</a>
      </li>
        
      <li class="nav-item">
        <a href="http://localhost:4000/tags/">Tags</a>
      </li>
         
    </ul>
  </nav>
  <script type="text/javascript">
  // based on http://stackoverflow.com/a/10300743/280842
  function gen_mail_to_link(hs, subject) {
    var lhs,rhs;
    var p = hs.split('@');
    lhs = p[0];
    rhs = p[1];
    document.write("<a class=\"social-link-item\" target=\"_blank\" href=\"mailto");
    document.write(":" + lhs + "@");
    document.write(rhs + "?subject=" + subject + "\"><i class=\"fa fa-fw fa-envelope\"></i><\/a>");
  }
</script>
<div class="social-links">
  <ul>
    
    <li><a href="http://twitter.com/imJvala" class="social-link-item" target="_blank"><i class="fa fa-fw fa-twitter"></i></a></li>
    
    
    <li><a href="http://linkedin.com/in/jayvala" class="social-link-item" target="_blank"><i class="fa fa-fw fa-linkedin"></i></a></li>
    
    
    
    
    <li><a href="http://github.com/jdvala" class="social-link-item" target="_blank"><i class="fa fa-fw fa-github"></i></a></li>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
  </ul>
</div>

</div>

      </div>
    </div>
    <div class="col s12 m9">
      <div class="post-listing">
        <a class="btn" href= "http://localhost:4000/" >
  Home
</a>



<div id="post">
  <header class="post-header">
    <h1 title="LSTM with 8 Classes">LSTM with 8 Classes</h1>
    <span class="post-meta">
      <span class="post-date">
        25 MAY 2018
      </span>
      â€¢
      <span class="read-time" title="Estimated read time">
  
  
    13 mins read
  
</span>

    </span>

  </header>

  <article class="post-content">
    <h1 id="new-lstm-with-8-classes">New LSTM with 8 classes</h1>

<p>In this script I will be using only 8 out of 32 classes that were originaly present in the dataset, this is necessary because the data in other classes is much less compared to these 8 classes, this makes it difficult for the neural network to learn anything off of those classes.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Word2Vec</span>
<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">imdb</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span>
<span class="kn">from</span> <span class="nn">keras.layers.embeddings</span> <span class="kn">import</span> <span class="n">Embedding</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/home/jay/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
</code></pre></div></div>

<p>I have already stored the senteces and their corresponding labels as stated in this <a href="https://jdvala.github.io/blog.io/thesis/2018/05/23/Creating-Data-Set-Again-!.html">post</a>. Hence I am going to use those sentences and labels.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Loading data
</span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'/home/jay/pickled/sent.pkl'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">sents</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'/home/jay/pickled/label.pkl'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">g</span><span class="p">:</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
</code></pre></div></div>

<p>As the model was not learning, I have decided to reduce the number of classes to 8, so I will pick up top 8 classes with maximum number of samples.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># lets count number of sample in each class
</span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="n">counter</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">label</span><span class="p">:</span>
    <span class="n">counter</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">+=</span><span class="mi">1</span>
</code></pre></div></div>

<p>As I have counted number of samples in each class, I will pick out top 8 classes from them and use only the 8</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">heapq</span>
<span class="n">classes</span> <span class="o">=</span> <span class="n">heapq</span><span class="o">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="nb">zip</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">counter</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
<span class="n">classes</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[(19018, 4),
 (15679, 24),
 (12455, 15),
 (10219, 3),
 (10011, 0),
 (7008, 26),
 (6606, 5),
 (6392, 11)]
</code></pre></div></div>

<p>These are the classes I am going to use for training the neural network.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_8</span> <span class="o">=</span><span class="p">[]</span>
<span class="n">label_8</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">sent</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">sents</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="mi">4</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">label</span> <span class="o">==</span><span class="mi">24</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="mi">15</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">label</span><span class="o">==</span><span class="mi">3</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">label</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">label</span><span class="o">==</span><span class="mi">26</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">label</span><span class="o">==</span><span class="mi">5</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">label</span><span class="o">==</span><span class="mi">11</span><span class="p">):</span>
        <span class="n">sample_8</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>
        <span class="n">label_8</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">len</span><span class="p">(</span><span class="n">sample_8</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>87388
</code></pre></div></div>

<p>As I have stated in my <a href="https://jdvala.github.io/blog.io/thesis/2018/05/16/Data-Discrepancies.html">Data Descrepancies post</a> that some sentences are very long. This is a problem when traning recurrent neural network with long sequences.
For example think of a situation where you have a sentence of 10 words and another sentence which is 200 word sentence which also happens to be the maximum length of sentence in dataset. So when you are padding all the sentences the sentence with 10 words will have 190 padded zeros, so you see how this is very inefficient and that there has to be some solution to things like this.
To tackle this problem what I think is a easy and effective solution is to break the 200 word sentence into number of smaller sentneces. This is however not ideal as we are loosing semantics and realations between words but this seams to be the only viable option right now. There are other options which you can learn about it <a href="https://machinelearningmastery.com/handle-long-sequences-long-short-term-memory-recurrent-neural-networks/">here</a>.</p>

<p>So for me what I will do is I will use sliding window or rolling window algorithm. To preserve the context of words in the longer sequence I will take smaller steps. For example, I have a sentence of 100 words, so I will first take a window of 20 words and make it into a sentence, then I will move five words from the starting and take another 20 words. So in my first sentence I will have words from index <code class="highlighter-rouge">0-19</code> and in my second sentence i will have words from index <code class="highlighter-rouge">4-24</code> and so on. This helps in preserving the context of the sentences.</p>

<p>The setting I used is <code class="highlighter-rouge">winSize=20</code> and <code class="highlighter-rouge">step=10</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">slidingWindow</span><span class="p">(</span><span class="n">sequence</span><span class="p">,</span><span class="n">winSize</span><span class="p">,</span><span class="n">step</span><span class="p">):</span>
    <span class="s">"""Returns a generator that will iterate through
       the defined chunks of input sequence. Input sequence
       must be sliceable."""</span>
    
    <span class="c1"># Pre-compute number of chunks to emit
</span>    <span class="n">numOfChunks</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(((</span><span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span><span class="o">-</span><span class="n">winSize</span><span class="p">)</span><span class="o">/</span><span class="n">step</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Do the work
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">numOfChunks</span><span class="o">*</span><span class="n">step</span><span class="p">,</span><span class="n">step</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">sequence</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">winSize</span><span class="p">]</span>
</code></pre></div></div>

<p>Make new sentece and labels list and check the length of every sentnce in <code class="highlighter-rouge">sample_8</code>, if there are more than 20 words in the sentence apply sliding window on it and store them into new list</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">new_sent</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">new_label</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sample_8</span><span class="p">,</span> <span class="n">label_8</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span><span class="o">&lt;=</span><span class="mi">20</span><span class="p">:</span>
        <span class="n">new_sent</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="n">new_label</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span><span class="o">&gt;</span><span class="mi">20</span><span class="p">:</span>
        <span class="n">slides</span> <span class="o">=</span> <span class="n">slidingWindow</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">slide</span> <span class="ow">in</span> <span class="n">slides</span><span class="p">:</span>
            <span class="n">new_sent</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">slide</span><span class="p">))</span>
            <span class="n">new_label</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">len</span><span class="p">(</span><span class="n">new_sent</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>329068
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Defining max_length
</span><span class="n">max_sent</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">new_sent</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="nb">len</span><span class="p">)</span>    <span class="c1"># Get the longest sentence in the list
</span><span class="n">max_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">max_sent</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>  <span class="c1"># split it and set the max_length
</span><span class="n">max_length</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>17
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Using Keras tokenizer
# Here I am using 10000 words to keep based on the word frequency
</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">Tokenizer</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

<span class="c1"># Tokenizing the sentences (This process may take some time depending on your corpus size)
</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">new_sent</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Lets see what our vocabulary size is
</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>   <span class="c1"># We are adding 1 here because it takes indexing from zero
</span><span class="n">vocab_size</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>15532
</code></pre></div></div>

<p>Even though it shows the vocab size to be 15532 it will only use 10000 words as we have spacified above.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Sentence encoding
</span><span class="n">sent_encoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">new_sent</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Start padding with the max_length
</span><span class="n">padded_sents</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">sent_encoded</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'post'</span><span class="p">)</span>
<span class="c1"># Note: We are using post padding
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Split the data into test and train
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span><span class="p">,</span> <span class="n">train_label</span><span class="p">,</span> <span class="n">test_label</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">padded_sents</span><span class="p">,</span> <span class="n">label_8</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="c1"># Define one_hot_encoder object
</span><span class="n">onehot_encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">train_labels</span> <span class="o">=</span> <span class="n">onehot_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">train_label</span><span class="p">,(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">onehot_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">test_label</span><span class="p">,(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
</code></pre></div></div>

<p>As I know that classes are unbalanced, the most common parctice is to use class weights to award penalty to a wrong prediction. For example, if we have 2 classes with <code class="highlighter-rouge">class_1 = 80</code> and <code class="highlighter-rouge">class_2 = 20</code> samples, then we can award a penalty to our network if the sample being predicted is of <code class="highlighter-rouge">class_2</code> and is predicted to <code class="highlighter-rouge">class_1</code>. To calculate penalty we take a reference class, I usually take the class with maximum samples, and then calculate penalty for other classes with this reference class. The penalty for <code class="highlighter-rouge">class_1 = (no. of sample in reference class)/(no. of sample in class_1)</code> which for our example will be <code class="highlighter-rouge">80/80=1</code> and for <code class="highlighter-rouge">class_2 = 80/20 = 4.0</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Computing the class weights
</span><span class="n">class_</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">ref_class</span> <span class="o">=</span> <span class="n">classes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">classes</span><span class="p">):</span>
    <span class="n">class_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="n">weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ref_class</span><span class="o">/</span><span class="n">j</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Creating dictonary out of the two lists
</span><span class="n">class_weight</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">class_</span><span class="p">,</span> <span class="n">weights</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">class_weight</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{0: 1.0,
 1: 1.2129600102047324,
 2: 1.5269369731031714,
 3: 1.8610431549075253,
 4: 1.8997103186494855,
 5: 2.713755707762557,
 6: 2.8788979715410234,
 7: 2.9752816020025032}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create sequential model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">reduce_rate</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s">'val_loss'</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                                                <span class="n">mode</span><span class="o">=</span><span class="s">'auto'</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">cooldown</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">min_lr</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">early_stop</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s">'val_loss'</span><span class="p">,</span> <span class="n">min_delta</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                                           <span class="n">patience</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'auto'</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">))</span>   <span class="c1"># adding embedding layer, which we have defined earlier
</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="n">recurrent_regularizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>     <span class="c1"># LSTM layer 
</span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="n">recurrent_regularizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.06</span><span class="p">),</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
<span class="c1">#model.add(Dropout(0.5))
</span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span> <span class="s">'adam'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> 
          <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span> <span class="p">,</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">reduce_rate</span><span class="p">,</span><span class="n">early_stop</span><span class="p">])</span>

</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/home/jay/.local/lib/python3.5/site-packages/keras/callbacks.py:928: UserWarning: <span class="sb">`</span>epsilon<span class="sb">`</span> argument is deprecated and will be removed, use <span class="sb">`</span>min_delta<span class="sb">`</span> insted.
  warnings.warn<span class="o">(</span><span class="s1">'`epsilon` argument is deprecated and '</span>
_________________________________________________________________
Layer <span class="o">(</span><span class="nb">type</span><span class="o">)</span>                 Output Shape              Param <span class="c">#   </span>
<span class="o">=================================================================</span>
embedding_1 <span class="o">(</span>Embedding<span class="o">)</span>      <span class="o">(</span>None, 20, 1000<span class="o">)</span>          15356000  
_________________________________________________________________
lstm_1 <span class="o">(</span>LSTM<span class="o">)</span>                <span class="o">(</span>None, 20, 30<span class="o">)</span>            123720    
_________________________________________________________________
dropout_1 <span class="o">(</span>Dropout<span class="o">)</span>          <span class="o">(</span>None, 20, 30<span class="o">)</span>            0         
_________________________________________________________________
lstm_2 <span class="o">(</span>LSTM<span class="o">)</span>                <span class="o">(</span>None, 50<span class="o">)</span>                16200     
_________________________________________________________________
dense_1 <span class="o">(</span>Dense<span class="o">)</span>              <span class="o">(</span>None, 8<span class="o">)</span>                 408       
<span class="o">=================================================================</span>
Total params: 15,496,328
Trainable params: 15,496,328
Non-trainable params: 0
Train on 68274 samples, validate on 7587 samples
Epoch 1/10
68274/68274 <span class="o">[==============================]</span> - 16s 227us/step - loss: 5.3191 - acc: 0.3646 - val_loss: 2.8831 - val_acc: 0.5347
Epoch 2/10
68274/68274 <span class="o">[==============================]</span> - 13s 192us/step - loss: 2.3372 - acc: 0.5942 - val_loss: 2.1347 - val_acc: 0.6038
Epoch 3/10
68274/68274 <span class="o">[==============================]</span> - 13s 193us/step - loss: 1.8782 - acc: 0.6433 - val_loss: 2.0397 - val_acc: 0.6060
Epoch 4/10
68274/68274 <span class="o">[==============================]</span> - 13s 194us/step - loss: 1.6965 - acc: 0.6656 - val_loss: 2.0175 - val_acc: 0.6137
Epoch 5/10
68274/68274 <span class="o">[==============================]</span> - 13s 193us/step - loss: 1.5890 - acc: 0.6803 - val_loss: 2.0452 - val_acc: 0.6171

Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
Epoch 00005: early stopping
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Accuracy: </span><span class="si">%.2</span><span class="s">f</span><span class="si">%%</span><span class="s">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>37365/37365 <span class="o">[==============================]</span> - 23s 622us/step
Accuracy: 61.45%
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Classification Report (Precision, Recall and F1-Score)
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="n">classificationReport</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">classificationReport</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>precision    recall  f1-score   support

          0       0.73      0.47      0.57      4268
          1       0.67      0.45      0.54      4169
          2       0.79      0.67      0.73      8563
          3       0.60      0.52      0.56      2816
          4       0.52      0.46      0.49      2400
          5       0.62      0.67      0.64      5409
          6       0.46      0.75      0.57      6799
          7       0.66      0.68      0.67      2941

avg / total       0.64      0.61      0.62     37365

<span class="o">[[</span>1989  106  147   80  245  769  890   42]
 <span class="o">[</span>  90 1886  370  130  287  230 1039  137]
 <span class="o">[</span>  58  215 5753  380  127  297 1506  227]
 <span class="o">[</span>  60   95  376 1469   52  155  537   72]
 <span class="o">[</span> 114  185  101   39 1108  316  506   31]
 <span class="o">[</span> 309   49  142  102  206 3635  882   84]
 <span class="o">[</span>  87  239  272  168   99  399 5114  421]
 <span class="o">[</span>   3   21   99   66   22   78  645 2007]]
</code></pre></div></div>

  </article>
</div>

<div class="share-buttons">
  <h6>Share on: </h6>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/articles/2018-05/RNN-Sequence-Classification-with-modifications" class="twitter btn" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/articles/2018-05/RNN-Sequence-Classification-with-modifications" class="facebook btn" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <!--<li>
      <a href="https://plus.google.com/share?url=http://localhost:4000/articles/2018-05/RNN-Sequence-Classification-with-modifications" class="google-plus btn" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>-->
    <li>
      <a href="https://news.ycombinator.com/submitlink?u=http://localhost:4000/articles/2018-05/RNN-Sequence-Classification-with-modifications" class="hacker-news btn" title="Share on Hacker News"><i class="fa fa-hacker-news"></i><span> Hacker News</span></a>
    </li>
    <li>
      <a href="https://www.reddit.com/submit?url=http://localhost:4000/articles/2018-05/RNN-Sequence-Classification-with-modifications" class="reddit btn" title="Share on Reddit"><i class="fa fa-reddit"></i><span> Reddit</span></a>
    </li>
  </ul>
</div><!-- end share-buttons -->


<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = 'jayvala';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>



        <footer>
  &copy; 2020 Jay Vala. Powered by <a href="http://jekyllrb.com/">Jekyll</a>, <a href="http://github.com/renyuanz/leonids/">leonids theme</a> made with <i class="fa fa-heart heart-icon"></i>
</footer>

      </div>
    </div>
  </div>
  <script type="text/javascript" src="https://http://localhost:4000/js/jquery-3.2.1.min.js"></script>
<script type="text/javascript" src="https://http://localhost:4000/js/main.js"></script>


</body>
</html>
